Sender: LSF System <lsfadmin@eu-lo-g2-019>
Subject: Job 219206468: <python models/votenet.py> in cluster <euler> Done

Job <python models/votenet.py> was submitted from host <eu-login-16> by user <tamariucai> in cluster <euler> at Fri May 20 23:00:25 2022
Job was executed on host(s) <eu-lo-g2-019>, in queue <gpu.4h>, as user <tamariucai> in cluster <euler> at Fri May 20 23:00:50 2022
</cluster/home/tamariucai> was used as the home directory.
</cluster/home/tamariucai/official/votenet-pmlr> was used as the working directory.
Started at Fri May 20 23:00:50 2022
Terminated at Fri May 20 23:01:31 2022
Results reported at Fri May 20 23:01:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python models/votenet.py
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   11.05 sec.
    Max Memory :                                 2048 MB
    Average Memory :                             1544.00 MB
    Total Requested Memory :                     2048.00 MB
    Delta Memory :                               0.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                7
    Run time :                                   68 sec.
    Turnaround time :                            66 sec.

The output (if any) follows:

Dataset has not been prepared. Use a random sample.
sa1_inds tensor([[    0, 14568, 13691,  ...,  4730, 16384,  7175]], device='cuda:0',
       dtype=torch.int32)
sa1_xyz tensor([[[0.2255, 0.5937, 0.6310],
         [0.9879, 0.0703, 0.0111],
         [0.9734, 0.0179, 0.9856],
         ...,
         [0.2606, 0.2817, 0.0280],
         [0.2708, 0.2942, 0.5716],
         [0.6215, 0.6651, 0.4832]]], device='cuda:0')
sa1_features tensor([[[1.6344, 1.1752, 2.1140,  ..., 1.1555, 1.4172, 2.1689],
         [2.3671, 3.0136, 0.2209,  ..., 3.1192, 2.7911, 2.4583],
         [2.0421, 1.4753, 1.8006,  ..., 1.0839, 2.1676, 2.1553],
         ...,
         [2.0736, 1.8887, 2.1349,  ..., 2.2452, 2.2785, 2.0108],
         [2.2172, 1.3578, 1.4120,  ..., 1.6463, 2.0155, 2.0967],
         [2.4368, 1.3447, 2.3730,  ..., 2.3267, 2.3526, 2.2955]]],
       device='cuda:0', grad_fn=<SqueezeBackward1>)
sa2_inds tensor([[   0,    1,    2,  ..., 1021, 1022, 1023]], device='cuda:0',
       dtype=torch.int32)
sa2_xyz tensor([[[0.2255, 0.5937, 0.6310],
         [0.9879, 0.0703, 0.0111],
         [0.9734, 0.0179, 0.9856],
         ...,
         [0.2457, 0.0089, 0.1438],
         [0.1519, 0.1055, 0.4288],
         [0.7425, 0.1656, 0.0427]]], device='cuda:0')
sa2_features tensor([[[1.3661, 1.6722, 1.9239,  ..., 2.1469, 2.2678, 1.7869],
         [1.7337, 2.3002, 2.3902,  ..., 1.9024, 1.6752, 2.2893],
         [2.5669, 2.0968, 2.6586,  ..., 3.4237, 3.2834, 1.9479],
         ...,
         [1.5105, 2.9478, 2.0062,  ..., 1.5659, 0.5715, 2.8212],
         [1.7605, 2.7169, 2.4184,  ..., 2.4571, 2.7347, 2.6417],
         [1.4643, 1.7760, 1.8221,  ..., 2.0220, 1.7042, 1.6091]]],
       device='cuda:0', grad_fn=<SqueezeBackward1>)
sa3_xyz tensor([[[2.2555e-01, 5.9374e-01, 6.3096e-01],
         [9.8785e-01, 7.0253e-02, 1.1068e-02],
         [9.7341e-01, 1.7925e-02, 9.8556e-01],
         ...,
         [2.8202e-01, 2.6197e-02, 2.1680e-01],
         [2.0822e-02, 5.4434e-01, 6.8843e-02],
         [8.7270e-01, 8.4535e-01, 3.8308e-04]]], device='cuda:0')
sa3_features tensor([[[1.4892, 1.3315, 1.0145,  ..., 1.3824, 2.1274, 2.5616],
         [2.2539, 2.3212, 0.5230,  ..., 2.3028, 2.3663, 2.3020],
         [2.5555, 1.1871, 1.4170,  ..., 1.1536, 1.0221, 0.8670],
         ...,
         [1.8182, 1.1651, 1.9761,  ..., 1.3415, 1.3701, 0.9017],
         [1.1320, 1.5251, 0.8333,  ..., 1.5846, 1.7563, 1.5873],
         [1.6572, 1.4827, 1.2719,  ..., 1.3812, 1.7823, 1.9631]]],
       device='cuda:0', grad_fn=<SqueezeBackward1>)
sa4_xyz tensor([[[2.2555e-01, 5.9374e-01, 6.3096e-01],
         [9.8785e-01, 7.0253e-02, 1.1068e-02],
         [9.7341e-01, 1.7925e-02, 9.8556e-01],
         [8.3302e-01, 9.9900e-01, 4.1741e-04],
         [9.9295e-01, 9.5583e-01, 9.8913e-01],
         [1.0744e-03, 7.0226e-02, 2.6321e-03],
         [5.0658e-02, 9.6795e-01, 2.4723e-02],
         [6.1110e-02, 2.7247e-02, 9.9341e-01],
         [9.2299e-01, 5.0757e-01, 5.0369e-01],
         [4.8381e-01, 1.2340e-02, 4.6169e-01],
         [4.8261e-01, 4.7806e-01, 3.8705e-02],
         [2.2437e-02, 9.8698e-01, 9.9683e-01],
         [6.2721e-01, 9.9477e-01, 5.6200e-01],
         [6.3996e-01, 5.0519e-01, 9.7554e-01],
         [1.1325e-02, 1.0724e-01, 4.7759e-01],
         [9.8719e-01, 1.5183e-02, 5.1037e-01],
         [9.8872e-01, 5.4039e-01, 5.0564e-03],
         [4.4042e-03, 5.3974e-01, 2.2254e-01],
         [5.1789e-01, 5.2499e-02, 9.5627e-01],
         [4.7757e-01, 9.9250e-01, 9.9535e-01],
         [7.0403e-03, 9.8246e-01, 5.4288e-01],
         [4.8222e-01, 3.4180e-03, 1.2762e-02],
         [2.3949e-02, 4.7423e-01, 9.8684e-01],
         [4.4174e-01, 8.6821e-01, 2.0197e-01],
         [9.9944e-01, 9.4246e-01, 3.7495e-01],
         [7.3954e-01, 2.3991e-01, 2.6791e-01],
         [5.7303e-01, 3.6265e-01, 6.0443e-01],
         [9.9912e-01, 3.9063e-01, 9.0644e-01],
         [2.7654e-01, 2.9133e-01, 2.8396e-01],
         [2.5879e-01, 2.2354e-01, 7.6188e-01],
         [7.5666e-01, 7.0258e-01, 2.5350e-01],
         [8.1651e-01, 7.5375e-01, 7.5703e-01],
         [3.1193e-01, 6.8637e-01, 9.8126e-01],
         [3.2033e-01, 9.1132e-01, 6.8710e-01],
         [5.0246e-01, 6.8379e-01, 4.7130e-01],
         [7.9018e-01, 1.6492e-01, 7.5533e-01],
         [2.1034e-01, 6.7714e-01, 1.5172e-02],
         [1.6922e-01, 7.7398e-01, 3.6234e-01],
         [9.2312e-03, 7.5211e-01, 7.8639e-01],
         [1.8185e-01, 1.0468e-03, 2.5361e-01],
         [1.0984e-02, 4.1863e-01, 5.1388e-01],
         [9.2319e-02, 3.5502e-01, 1.7887e-04],
         [3.8298e-01, 3.7016e-01, 9.7770e-01],
         [5.3149e-01, 7.1660e-01, 7.9869e-01],
         [6.1388e-01, 7.3063e-01, 5.0465e-03],
         [7.3589e-01, 9.9163e-01, 2.8591e-01],
         [7.6158e-01, 3.7738e-01, 6.9349e-03],
         [9.5335e-01, 9.9288e-01, 7.1241e-01],
         [9.9055e-01, 3.8116e-01, 2.3395e-01],
         [7.3095e-01, 9.9114e-01, 8.8591e-01],
         [5.1993e-01, 4.0843e-01, 3.3157e-01],
         [9.7300e-01, 6.6219e-01, 9.6209e-01],
         [1.4989e-02, 2.4581e-01, 2.4685e-01],
         [7.8462e-01, 4.3359e-01, 7.4965e-01],
         [7.3104e-01, 8.0569e-03, 1.0726e-01],
         [1.4731e-03, 2.4927e-01, 8.2462e-01],
         [1.1883e-01, 2.7077e-03, 7.2529e-01],
         [2.6986e-01, 5.5543e-01, 2.5398e-01],
         [8.1461e-01, 7.9378e-01, 4.9630e-01],
         [9.9569e-01, 2.7419e-01, 6.0169e-01],
         [3.0094e-01, 1.9400e-01, 9.8668e-03],
         [3.9804e-01, 7.0291e-03, 7.3168e-01],
         [5.7473e-01, 9.9946e-01, 7.6306e-03],
         [3.8869e-01, 9.7014e-01, 4.4506e-01],
         [9.8228e-01, 7.6773e-01, 1.2561e-01],
         [7.2886e-01, 3.9263e-02, 5.2873e-01],
         [9.6263e-01, 2.1917e-04, 2.5413e-01],
         [5.0862e-01, 1.4056e-01, 2.2500e-01],
         [3.1619e-01, 9.8020e-01, 1.5072e-02],
         [7.7231e-01, 2.6893e-01, 9.8229e-01],
         [1.4014e-02, 9.9424e-01, 2.7070e-01],
         [2.7647e-01, 1.4154e-01, 5.1268e-01],
         [4.2412e-01, 4.9690e-01, 7.7114e-01],
         [2.4754e-01, 9.2036e-01, 9.2070e-01],
         [3.1566e-01, 3.7622e-01, 5.5846e-01],
         [2.9236e-01, 1.3506e-01, 9.8525e-01],
         [6.9720e-01, 7.7503e-01, 9.8844e-01],
         [1.4382e-02, 6.6878e-01, 5.4315e-01],
         [5.6039e-01, 2.6980e-01, 8.2427e-01],
         [9.9133e-01, 5.9086e-01, 7.1403e-01],
         [7.8765e-01, 2.9946e-01, 4.9050e-01],
         [6.8975e-01, 5.3860e-01, 4.2819e-01],
         [5.3694e-01, 6.3708e-01, 2.1508e-01],
         [4.2894e-02, 7.6113e-01, 1.6443e-01],
         [1.1371e-02, 5.2610e-01, 7.5462e-01],
         [5.6492e-01, 2.6212e-01, 7.8256e-03],
         [9.8246e-01, 3.3335e-02, 7.5845e-01],
         [6.4839e-01, 5.9185e-01, 6.4976e-01],
         [9.9166e-01, 3.1324e-01, 1.8489e-02],
         [1.9871e-01, 4.2285e-01, 8.4685e-01],
         [6.2173e-02, 9.8458e-01, 7.7767e-01],
         [6.2045e-01, 1.5587e-03, 7.4176e-01],
         [9.5556e-01, 6.1680e-01, 3.0450e-01],
         [7.7869e-01, 4.8502e-01, 2.2529e-01],
         [9.7991e-01, 1.8907e-01, 3.7599e-01],
         [2.2126e-01, 9.6280e-01, 2.2280e-01],
         [5.8918e-01, 1.9817e-01, 4.3897e-01],
         [7.1532e-02, 7.7833e-01, 9.9789e-01],
         [1.5719e-01, 8.2900e-01, 5.7506e-01],
         [5.6277e-01, 9.4027e-01, 7.5884e-01],
         [4.7097e-03, 6.3033e-01, 2.8622e-03],
         [6.3305e-01, 8.4934e-01, 4.0371e-01],
         [9.9342e-01, 7.8364e-01, 6.2881e-01],
         [7.7406e-02, 2.4315e-01, 6.2404e-01],
         [7.6449e-01, 6.1615e-02, 9.3627e-01],
         [4.6554e-01, 1.6078e-01, 6.0736e-01],
         [7.8673e-01, 5.8424e-01, 3.2874e-02],
         [4.0813e-01, 7.9437e-01, 1.2866e-03],
         [1.8195e-01, 4.3603e-01, 3.9839e-01],
         [8.3058e-01, 1.9029e-01, 7.0968e-02],
         [7.0359e-01, 2.5381e-02, 3.1139e-01],
         [2.0783e-01, 6.3385e-03, 4.9570e-02],
         [3.1074e-01, 3.9031e-01, 1.0824e-01],
         [8.1329e-01, 9.9957e-01, 4.7376e-01],
         [3.8809e-01, 7.2333e-01, 6.5193e-01],
         [5.9296e-01, 7.9677e-01, 6.1295e-01],
         [7.9412e-01, 8.0578e-01, 6.5659e-02],
         [8.4230e-01, 5.0642e-01, 9.5586e-01],
         [3.2779e-01, 5.6150e-01, 4.5695e-01],
         [9.2781e-01, 9.8856e-01, 1.7652e-01],
         [1.9032e-01, 9.9664e-01, 4.4274e-01],
         [2.1903e-01, 7.7280e-01, 7.8893e-01],
         [3.4571e-01, 7.7504e-02, 3.3373e-01],
         [1.3002e-01, 6.0974e-01, 8.8947e-01],
         [4.9055e-01, 7.9184e-01, 9.7535e-01],
         [6.3535e-01, 8.6322e-01, 1.6387e-01],
         [3.7294e-01, 7.1105e-01, 3.1137e-01],
         [9.5306e-01, 1.8229e-01, 8.8023e-01],
         [7.7362e-01, 9.0769e-01, 6.4872e-01],
         [1.5748e-01, 5.0877e-01, 1.0708e-01],
         [1.4937e-01, 1.5975e-01, 3.5703e-01],
         [1.1654e-01, 1.9076e-01, 9.7816e-02],
         [5.3981e-01, 9.9569e-01, 2.9961e-01],
         [8.6620e-01, 8.2517e-01, 9.2262e-01],
         [2.7175e-01, 7.9188e-01, 1.6783e-01],
         [1.0170e-01, 2.0925e-01, 9.9013e-01],
         [4.1028e-01, 3.2037e-01, 7.1303e-01],
         [4.4978e-01, 5.6399e-01, 9.5674e-01],
         [6.1174e-01, 4.2228e-01, 1.5946e-01],
         [4.8364e-01, 5.2728e-01, 5.9449e-01],
         [4.0018e-01, 2.7308e-01, 4.2078e-01],
         [2.2913e-03, 8.3164e-01, 4.1796e-01],
         [2.4267e-01, 4.8913e-03, 8.6385e-01],
         [1.5151e-01, 2.7061e-04, 5.3192e-01],
         [3.7804e-01, 1.2010e-02, 1.6480e-01],
         [3.7549e-01, 6.1623e-01, 1.1621e-01],
         [3.2857e-01, 8.0319e-01, 4.9342e-01],
         [8.4081e-01, 6.3667e-01, 6.1767e-01],
         [6.9539e-01, 5.9963e-01, 8.2494e-01],
         [1.6498e-01, 4.2631e-01, 6.6243e-01],
         [9.9664e-01, 7.6795e-01, 8.1128e-01],
         [9.9601e-01, 2.0973e-01, 1.6638e-01],
         [8.8571e-01, 8.1245e-01, 3.2330e-01],
         [5.8841e-01, 2.4203e-01, 9.9962e-01],
         [8.7141e-01, 1.2363e-01, 5.9751e-01],
         [4.3827e-01, 3.0468e-01, 2.0053e-01],
         [8.9599e-03, 5.6113e-01, 4.0162e-01],
         [9.7530e-01, 6.7624e-01, 4.8297e-01],
         [2.8817e-01, 6.0944e-01, 7.9989e-01],
         [6.7812e-01, 2.2083e-01, 6.2946e-01],
         [9.9786e-01, 3.6262e-01, 4.3594e-01],
         [7.5304e-03, 1.8085e-02, 2.6455e-01],
         [6.0239e-01, 4.6459e-01, 7.6119e-01],
         [4.0253e-01, 8.6429e-01, 8.4324e-01],
         [9.8937e-01, 4.1802e-01, 7.3483e-01],
         [1.6267e-01, 6.2191e-01, 4.5566e-01],
         [9.8694e-01, 9.0854e-01, 2.4340e-02],
         [8.5613e-01, 3.3579e-02, 3.9898e-01],
         [1.4503e-01, 3.6950e-01, 2.0697e-01],
         [4.6282e-01, 9.7650e-01, 6.0240e-01],
         [7.4261e-01, 4.4826e-01, 5.8616e-01],
         [2.7857e-02, 3.8676e-01, 3.4933e-01],
         [1.8192e-01, 8.6316e-01, 4.4515e-02],
         [3.3400e-01, 1.7421e-01, 1.7777e-01],
         [8.5037e-01, 3.9896e-01, 3.6468e-01],
         [6.7607e-01, 6.9891e-01, 5.0506e-01],
         [3.8149e-01, 1.3669e-01, 8.3630e-01],
         [2.6531e-01, 4.8825e-01, 9.9155e-01],
         [4.2321e-01, 4.9195e-01, 2.1738e-01],
         [8.3184e-01, 9.6955e-02, 2.2520e-01],
         [6.6396e-01, 1.8369e-01, 1.1380e-01],
         [1.1317e-01, 2.9767e-01, 4.7192e-01],
         [1.2611e-01, 6.4463e-01, 2.5212e-01],
         [8.1834e-01, 2.9818e-01, 6.5976e-01],
         [6.9751e-01, 3.6749e-01, 8.7657e-01],
         [7.1278e-01, 9.9636e-01, 1.1317e-01],
         [1.9814e-01, 3.3933e-01, 9.9864e-01],
         [7.9273e-02, 1.0871e-01, 8.4642e-01],
         [9.1274e-01, 5.5471e-01, 1.6110e-01],
         [3.6375e-01, 4.2318e-01, 3.7022e-01],
         [6.7175e-01, 3.7981e-01, 4.0519e-01],
         [8.9102e-01, 3.1424e-01, 8.1174e-01],
         [9.9957e-01, 9.3704e-01, 5.6894e-01],
         [3.4156e-01, 8.6770e-01, 3.2699e-01],
         [8.4377e-01, 3.1989e-01, 1.7756e-01],
         [6.6862e-01, 8.3888e-01, 8.2064e-01],
         [8.0801e-01, 6.6148e-01, 9.5499e-01],
         [2.1692e-01, 9.9398e-01, 6.0014e-01],
         [5.8628e-01, 2.8638e-01, 2.5571e-01],
         [6.1248e-01, 1.2270e-01, 8.5008e-01],
         [2.7640e-01, 4.0952e-02, 6.3440e-01],
         [4.6427e-01, 4.0655e-01, 4.9462e-01],
         [4.5955e-01, 1.5038e-01, 6.5653e-02],
         [3.1640e-01, 5.1216e-01, 8.4747e-03],
         [6.1352e-01, 5.5942e-01, 5.9322e-03],
         [4.6963e-01, 8.3259e-01, 4.3278e-01],
         [6.6315e-01, 6.4469e-01, 1.2608e-01],
         [8.3416e-01, 6.1057e-01, 3.9955e-01],
         [5.7294e-01, 6.5674e-01, 9.5190e-01],
         [2.0257e-03, 4.3044e-01, 9.9623e-02],
         [6.5040e-01, 5.5163e-01, 2.8001e-01],
         [4.6555e-01, 5.6009e-01, 3.8764e-01],
         [2.6590e-02, 8.9326e-02, 6.3888e-01],
         [9.7317e-02, 6.4413e-01, 7.0866e-01],
         [8.4020e-01, 9.3253e-03, 8.0926e-01],
         [7.2193e-02, 1.2423e-02, 1.2617e-01],
         [9.1222e-01, 9.7695e-01, 8.6116e-01],
         [4.3740e-03, 6.4349e-01, 9.7307e-01],
         [1.6119e-02, 8.8371e-01, 6.7282e-01],
         [5.7614e-01, 2.9198e-02, 1.4604e-01],
         [3.6169e-01, 9.9393e-01, 1.7068e-01],
         [1.1628e-01, 8.6713e-01, 8.6563e-01],
         [8.5724e-01, 5.9733e-01, 7.8524e-01],
         [5.3080e-01, 8.7365e-03, 6.0545e-01],
         [2.2286e-01, 1.6429e-02, 3.9982e-01],
         [5.3685e-01, 7.7029e-01, 2.8618e-01],
         [8.2705e-01, 9.6083e-01, 9.9828e-01],
         [8.8854e-01, 4.9460e-01, 6.5273e-01],
         [2.2835e-01, 2.4442e-01, 6.1159e-01],
         [5.1363e-01, 4.1873e-01, 8.7385e-01],
         [4.2041e-01, 3.0108e-01, 1.7060e-02],
         [8.2515e-03, 3.7480e-01, 7.4472e-01],
         [1.0019e-01, 5.2705e-01, 5.7431e-01],
         [4.9121e-01, 3.1461e-03, 2.7839e-01],
         [2.1028e-01, 9.7730e-01, 7.8372e-01],
         [7.8027e-01, 1.6052e-01, 4.0330e-01],
         [5.1693e-01, 7.4996e-01, 1.2237e-01],
         [4.7450e-01, 8.2705e-01, 7.0957e-01],
         [9.7948e-01, 2.1940e-01, 7.3682e-01],
         [9.6304e-02, 8.6949e-01, 2.4621e-01],
         [9.3916e-01, 6.7661e-01, 1.6625e-02],
         [4.7507e-01, 9.1103e-01, 6.5197e-02],
         [3.4034e-01, 5.0546e-01, 6.1973e-01],
         [9.9088e-01, 8.1919e-01, 4.7073e-01],
         [3.4889e-01, 8.2701e-01, 9.7173e-01],
         [7.4754e-01, 8.4741e-01, 3.0197e-01],
         [3.8144e-01, 1.2677e-02, 9.0962e-01],
         [7.5906e-01, 4.8254e-02, 6.7702e-01],
         [6.3331e-01, 8.9775e-01, 9.4992e-01],
         [5.3478e-01, 9.7075e-01, 4.4088e-01],
         [4.1430e-01, 2.7533e-01, 8.5350e-01],
         [3.7192e-01, 9.9584e-01, 7.9089e-01],
         [8.7919e-01, 4.3170e-01, 9.5066e-02],
         [2.8304e-03, 7.9392e-01, 3.0882e-02],
         [6.3509e-01, 6.5923e-01, 3.7320e-01],
         [8.9240e-01, 3.4606e-01, 9.9279e-01]]], device='cuda:0')
sa4_features tensor([[[2.4873, 2.4217, 1.8259,  ..., 2.5043, 2.5017, 2.4728],
         [1.6184, 1.7801, 1.6749,  ..., 1.5665, 1.6734, 1.6491],
         [2.3059, 2.3076, 2.3879,  ..., 2.1210, 2.3140, 2.4137],
         ...,
         [1.7040, 1.7931, 1.5823,  ..., 1.8571, 1.7122, 1.5719],
         [1.6489, 1.1364, 1.8301,  ..., 2.3274, 1.6514, 1.7717],
         [1.6638, 1.8188, 1.5812,  ..., 1.1389, 1.6869, 1.5314]]],
       device='cuda:0', grad_fn=<SqueezeBackward1>)
fp2_features tensor([[[7.1716e-01, 7.7202e-01, 2.0020e+00,  ..., 1.2640e+00,
          0.0000e+00, 1.1950e+00],
         [0.0000e+00, 5.3440e-01, 1.5476e+00,  ..., 1.9264e+00,
          1.9578e-03, 1.2205e+00],
         [2.2704e-01, 1.5897e+00, 2.2417e+00,  ..., 1.1388e+00,
          2.6216e-01, 0.0000e+00],
         ...,
         [0.0000e+00, 0.0000e+00, 2.5184e+00,  ..., 0.0000e+00,
          0.0000e+00, 7.3780e-02],
         [0.0000e+00, 8.1600e-01, 1.0639e+00,  ..., 5.6681e-01,
          1.6762e-01, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 5.0061e-01,  ..., 0.0000e+00,
          4.4871e-02, 8.3959e-01]]], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
fp2_xyz tensor([[[0.2255, 0.5937, 0.6310],
         [0.9879, 0.0703, 0.0111],
         [0.9734, 0.0179, 0.9856],
         ...,
         [0.2457, 0.0089, 0.1438],
         [0.1519, 0.1055, 0.4288],
         [0.7425, 0.1656, 0.0427]]], device='cuda:0')
fp2_inds tensor([[    0, 14568, 13691,  ...,  8301,  7930, 16154]], device='cuda:0',
       dtype=torch.int32)
seed_inds tensor([[    0, 14568, 13691,  ...,  8301,  7930, 16154]], device='cuda:0',
       dtype=torch.int32)
seed_xyz tensor([[[0.2255, 0.5937, 0.6310],
         [0.9879, 0.0703, 0.0111],
         [0.9734, 0.0179, 0.9856],
         ...,
         [0.2457, 0.0089, 0.1438],
         [0.1519, 0.1055, 0.4288],
         [0.7425, 0.1656, 0.0427]]], device='cuda:0')
seed_features tensor([[[7.1716e-01, 7.7202e-01, 2.0020e+00,  ..., 1.2640e+00,
          0.0000e+00, 1.1950e+00],
         [0.0000e+00, 5.3440e-01, 1.5476e+00,  ..., 1.9264e+00,
          1.9578e-03, 1.2205e+00],
         [2.2704e-01, 1.5897e+00, 2.2417e+00,  ..., 1.1388e+00,
          2.6216e-01, 0.0000e+00],
         ...,
         [0.0000e+00, 0.0000e+00, 2.5184e+00,  ..., 0.0000e+00,
          0.0000e+00, 7.3780e-02],
         [0.0000e+00, 8.1600e-01, 1.0639e+00,  ..., 5.6681e-01,
          1.6762e-01, 0.0000e+00],
         [0.0000e+00, 0.0000e+00, 5.0061e-01,  ..., 0.0000e+00,
          4.4871e-02, 8.3959e-01]]], device='cuda:0',
       grad_fn=<SqueezeBackward1>)
vote_xyz tensor([[[ 0.8108,  0.7700,  0.8221],
         [ 1.0658, -0.3353,  0.3880],
         [ 0.8108, -0.1351,  1.7719],
         ...,
         [ 0.5182, -0.0507, -0.5668],
         [ 0.4211,  0.3942,  0.6225],
         [ 1.0668,  0.0166,  0.1693]]], device='cuda:0',
       grad_fn=<ViewBackward>)
vote_features tensor([[[ 0.0499,  0.0296,  0.0530,  ...,  0.0419,  0.0261,  0.0948],
         [ 0.0451,  0.0454,  0.0800,  ...,  0.1071,  0.0224,  0.1063],
         [ 0.0230,  0.1163,  0.1116,  ...,  0.0538,  0.0293,  0.0310],
         ...,
         [ 0.0150, -0.0084,  0.1086,  ..., -0.0131,  0.0361, -0.0403],
         [ 0.0096,  0.0281,  0.0783,  ...,  0.0770,  0.0028, -0.0444],
         [ 0.0120, -0.0314,  0.0424,  ..., -0.0252,  0.0083,  0.0918]]],
       device='cuda:0', grad_fn=<DivBackward0>)
aggregated_vote_xyz tensor([[[ 0.8108,  0.7700,  0.8221],
         [-0.1984, -0.7467,  0.4580],
         [ 0.8836,  2.1767, -0.1251],
         [ 0.1110,  1.6985,  2.0129],
         [-0.6650,  0.7721,  0.1392],
         [ 1.3662,  0.2361, -0.5685],
         [ 0.6296,  0.0121,  2.1877],
         [ 0.9366, -0.3265,  0.3764],
         [ 0.3947,  0.8942, -0.5119],
         [-0.3050,  0.3968,  1.6170],
         [-0.3946,  1.8552,  0.3392],
         [ 0.4736, -0.3238, -0.6057],
         [ 1.4498,  1.0895,  1.5857],
         [ 1.1822,  1.2339,  0.0281],
         [ 0.0995,  0.1572,  0.1683],
         [ 0.4388, -0.0649,  1.1743],
         [-0.0444,  1.2657,  1.1545],
         [ 0.5804,  1.7464,  0.6234],
         [-0.6510, -0.1375,  0.9368],
         [ 1.5755,  0.4167,  0.6300],
         [ 0.5977,  1.0283,  1.8371],
         [ 0.1405,  0.9616,  0.2879],
         [ 1.1519,  0.2489,  1.3408],
         [ 0.1624,  1.8384, -0.2205],
         [ 1.4597,  1.1765,  0.8070],
         [ 0.9732,  0.4454,  0.0499],
         [-0.0897,  0.4834,  0.9106],
         [-0.5137,  0.2973, -0.3653],
         [ 0.7024,  1.4892,  1.2342],
         [ 0.3898, -0.5311,  0.0151],
         [ 0.3777,  0.6327,  1.3430],
         [ 1.3514,  1.7801, -0.2055],
         [ 0.2583, -0.3592,  0.5978],
         [ 0.6235,  0.2448,  0.5802],
         [ 1.4598,  0.8291, -0.6222],
         [ 0.6465,  1.5179, -0.0736],
         [-0.1016, -0.2405,  1.3614],
         [-0.4587,  0.0865,  0.3607],
         [ 0.4485,  0.3064, -0.4753],
         [-0.4332,  1.3059,  0.4802],
         [ 1.1129,  1.6554,  0.4473],
         [ 0.6844,  1.1698,  0.4398],
         [ 0.7664, -0.1041, -0.1076],
         [ 0.7628,  0.3322,  1.7274],
         [ 0.1295,  1.5525,  0.2530],
         [ 1.4771,  0.2210,  0.0636],
         [ 1.4747, -0.4178,  0.3995],
         [ 0.7444,  0.9266, -0.0441],
         [ 1.1937,  0.8200,  0.3720],
         [ 0.9397, -0.0536,  0.9554],
         [ 1.2271,  1.4270,  1.2217],
         [ 0.1269,  1.7490,  1.2676],
         [ 0.2219,  0.8922,  0.9163],
         [ 1.0191,  0.7259,  1.4680],
         [ 1.0154,  0.9162,  2.0996],
         [-0.0606,  0.0118,  0.7081],
         [ 0.2813,  0.2346,  1.6458],
         [ 1.0029,  0.7162, -0.4138],
         [ 0.4335,  2.0943,  0.1085],
         [ 0.1358,  0.8931,  1.9095],
         [ 0.2312,  0.5906, -0.0105],
         [ 0.2304,  1.4459,  0.7650],
         [-0.2089,  0.6515,  0.4787],
         [-0.7441,  0.4364,  0.5179],
         [ 1.1468,  0.0967,  0.5533],
         [ 0.5160,  0.6829,  0.3756],
         [ 0.0640,  1.0779, -0.1668],
         [ 0.6540,  1.0207,  1.2811],
         [ 0.8978,  0.2962, -0.6195],
         [ 0.8108, -0.1351,  1.7719],
         [ 0.7723,  1.4532,  1.9070],
         [-0.0087,  2.0787,  0.2204],
         [ 0.9575,  1.2744,  0.8902],
         [ 1.4054,  0.7682, -0.0257],
         [ 0.5247, -0.0795,  0.2813],
         [-0.2642,  0.6273,  0.0023],
         [ 0.7539,  0.4362,  1.1143],
         [-0.2742, -0.3251,  0.3429],
         [ 1.5802, -0.0168,  0.7048],
         [-0.1261,  1.1037,  0.7186],
         [ 1.2091,  0.4167,  0.8648],
         [ 0.2208,  0.4003,  0.5254],
         [ 0.1399,  0.0308, -0.2454],
         [ 1.1949,  0.8009,  1.0820],
         [ 0.0649,  0.1702,  1.1626],
         [-0.4436,  0.6850,  1.0360],
         [ 0.4312,  1.5291, -0.4332],
         [-0.3173,  0.9955,  0.2098],
         [ 0.0143,  0.7057,  1.5572],
         [ 0.9743,  0.4808,  0.5263],
         [ 0.5592, -0.5580,  0.3902],
         [ 0.0441,  1.2777,  2.0150],
         [ 0.1154, -0.2975,  0.9754],
         [ 0.4130,  0.4143,  0.8829],
         [ 1.0771,  1.2412,  0.5063],
         [ 0.4868,  0.2967,  0.0829],
         [ 1.0668,  0.0166,  0.1693],
         [-0.1190,  1.4445, -0.0416],
         [ 0.5292,  1.1932,  0.9507],
         [ 0.6396, -0.2782,  0.6431],
         [ 0.3902, -0.1350,  1.6354],
         [ 0.3491,  0.0298,  0.8161],
         [ 1.4732,  1.6540,  0.3300],
         [-0.1769, -0.0992,  0.0568],
         [-0.1357,  0.3407, -0.1948],
         [ 0.6550,  0.4922, -0.1830],
         [ 0.6605,  0.0190, -0.6115],
         [ 0.1569, -0.8026,  0.4184],
         [ 0.7695,  1.7756,  0.1456],
         [ 0.7889,  0.0842,  1.2482],
         [ 0.1298,  0.7224, -0.3225],
         [ 0.3171,  1.1850,  0.4917],
         [ 0.3773,  0.5816,  1.6875],
         [ 1.4117, -0.0773,  0.3958],
         [ 0.4651,  1.3269,  0.2174],
         [-0.1716,  0.3552,  0.3165],
         [ 0.5213,  0.7538,  0.9984],
         [ 0.0319,  1.3913,  1.4596],
         [ 1.1575, -0.2751,  0.8234],
         [ 0.7851,  1.4237,  0.6362],
         [-0.2398,  0.0417,  0.9909],
         [ 0.4181,  1.3047,  1.7769],
         [ 0.1217, -0.3424,  0.2924],
         [ 0.3358,  0.7217,  0.6557],
         [-0.0542,  0.8824,  1.0985],
         [ 0.7735,  1.2701,  0.1119],
         [ 0.3777,  0.2346,  1.3299],
         [ 0.7807,  0.8616,  0.4933]]], device='cuda:0',
       grad_fn=<CopyBackwards>)
aggregated_vote_inds tensor([[   0,  290,  119,  216,  278,  470,  567,  661,  106,   84,    6,  528,
          300,  305,  802,  895,  289,  496,  247,  736,  327,  757,  556,  172,
          309,   46,  561,  392,   70, 1003,  774,  678, 1020,   39,  483,  511,
         1008,  745,  315,  302,  780,  360,  297,  428,  454,  481,  714,  574,
          109,  110,  396,  865,  906,  340,  260,  642,  255,  252,  936,  133,
          383,  357,  861,  497,  627,  175,   71,  863,  419,    2,  778,  365,
           43,   16,  280,  688,  932,  522,  710,  440,  946,  674,  450,  643,
          783,  348,    3,   68,  142,  458,  155,  659,  413,   32,  952,   28,
         1023,  935,  637,  749,  938,  618,  166,   74,  111,  781,  553,  611,
          424,  857,  410,  614,  283,  985,  445,  813,  333,  954,   15,  898,
           61,  423,  202,  599,  622,  547,  725, 1002]], device='cuda:0',
       dtype=torch.int32)
objectness_scores tensor([[[ 0.1413,  0.3304],
         [-0.2383,  0.3690],
         [-0.0042,  0.5256],
         [-0.3506,  0.5601],
         [-0.5175,  0.5330],
         [-0.2617,  0.0416],
         [-0.2618,  0.4934],
         [ 0.1281,  0.4244],
         [-0.3783,  0.5346],
         [-0.4389,  0.5973],
         [-0.4003,  0.3964],
         [ 0.2144,  0.3719],
         [-0.3568,  0.5232],
         [ 0.6368,  0.1144],
         [ 0.3574,  0.5617],
         [-0.0448,  0.7346],
         [ 0.3843,  0.7252],
         [ 0.1363,  1.4803],
         [-0.1312,  0.1523],
         [-0.4653,  0.3785],
         [-0.2367,  0.7979],
         [ 0.2384,  0.1452],
         [-0.1422,  0.6609],
         [-0.4245,  0.8437],
         [ 0.1354,  0.1098],
         [ 0.3634,  0.3370],
         [-0.1434,  0.3838],
         [-0.3882,  0.2874],
         [ 0.6212,  0.7276],
         [-0.6594,  0.4006],
         [ 0.0407,  0.7282],
         [ 0.2832,  0.6696],
         [-0.2944,  1.2471],
         [ 0.3855, -0.0174],
         [-0.3348,  0.4436],
         [ 0.1669,  0.7038],
         [-0.3604,  0.9897],
         [-0.2219,  1.0051],
         [ 0.5352, -0.0873],
         [ 0.1800,  0.3994],
         [ 0.8451,  0.3527],
         [ 0.6342,  0.4210],
         [-0.5355,  0.6569],
         [ 0.1424,  0.8752],
         [ 0.1518,  1.1024],
         [ 0.0312,  0.0047],
         [-0.2515,  0.5425],
         [-0.0727,  0.7104],
         [ 0.5898,  0.0931],
         [-0.4605,  0.4651],
         [-0.0190,  0.1813],
         [-0.1598,  0.8781],
         [ 0.5206,  0.7432],
         [ 0.4561,  0.3828],
         [-0.4786,  0.7245],
         [ 0.1874,  0.7617],
         [-0.1554,  1.5450],
         [-0.1259,  0.9988],
         [-0.0303,  0.4569],
         [-0.2183,  0.1356],
         [ 0.3391,  0.6662],
         [-0.2420,  0.6151],
         [ 0.2712,  0.9021],
         [-0.5826,  0.5873],
         [ 0.1140,  0.0652],
         [ 0.4930,  0.4294],
         [-0.2724,  0.4241],
         [-0.1286,  0.6205],
         [-0.0849,  0.2741],
         [-0.1891,  0.6529],
         [-0.0660,  0.2097],
         [-0.3171,  0.5520],
         [ 0.1816,  0.4171],
         [ 0.7123,  0.5222],
         [-0.6264,  0.6658],
         [-0.2043,  0.6722],
         [ 0.2930,  1.0199],
         [-0.6082,  0.4018],
         [ 0.1145,  0.7039],
         [-0.0380,  0.8160],
         [ 0.3176,  0.6834],
         [-0.1354,  0.7462],
         [-0.0512,  0.2604],
         [ 0.8051,  0.3221],
         [ 0.0890,  0.5691],
         [-0.7893,  0.0605],
         [-0.1960,  0.6209],
         [ 0.2007,  0.4904],
         [ 0.1091,  0.5164],
         [ 0.3753,  0.6778],
         [-0.0387,  0.4781],
         [-0.4121,  0.2348],
         [-0.3510,  0.8758],
         [-0.3397,  0.5758],
         [ 0.6563, -0.0947],
         [-0.0325,  0.5387],
         [ 0.1730, -0.1794],
         [ 0.0212,  0.6848],
         [ 0.1572,  0.4142],
         [ 0.1359, -0.0613],
         [-0.5582,  0.4132],
         [-0.1431,  0.3142],
         [-0.2029,  0.3822],
         [ 0.0759,  0.5525],
         [ 0.0796,  0.0729],
         [ 0.2037,  0.8731],
         [ 0.0625,  0.2527],
         [-0.2588,  0.1877],
         [-0.2566,  0.7042],
         [ 0.2445,  0.5936],
         [-0.3326,  0.5465],
         [ 0.4061,  0.4659],
         [-0.2519,  0.8792],
         [ 0.2443, -0.0722],
         [ 0.3635,  1.2572],
         [-0.3382,  0.4355],
         [-0.0980,  0.8968],
         [-0.3570,  0.4970],
         [-0.0673,  0.0928],
         [ 0.7671,  0.6163],
         [-0.1879, -0.0568],
         [-0.6955,  0.7091],
         [-0.0547,  0.2176],
         [ 0.5079,  0.2445],
         [-0.2442,  0.6951],
         [ 0.1306,  0.4097],
         [-0.5712,  0.4658],
         [ 0.3046,  0.3928]]], device='cuda:0', grad_fn=<SliceBackward>)
center tensor([[[ 0.4489,  1.2453,  1.0330],
         [-0.3735, -0.8006,  0.6896],
         [-0.4261,  1.5656, -0.4406],
         [-0.5811,  1.4148,  1.5167],
         [-1.0473,  0.5311, -0.1452],
         [ 0.8280, -0.3400, -0.6513],
         [ 0.1484, -0.1895,  1.6361],
         [ 0.6748,  0.2082,  0.8882],
         [ 0.4438,  1.2224, -0.6483],
         [-0.5030,  0.5100,  1.6313],
         [-0.4080,  1.8543,  0.3027],
         [-0.3637,  0.0233, -0.7143],
         [ 1.0253,  1.1405,  1.3596],
         [ 0.3312,  1.7506, -0.0567],
         [-0.3789,  0.5865,  0.5618],
         [-0.3512,  0.8583,  1.3145],
         [-0.6077,  1.4752,  1.1845],
         [-0.4213,  1.4532,  0.7760],
         [-1.4304, -0.0237,  1.1699],
         [ 1.3638,  0.3147,  0.2740],
         [ 0.2774,  0.6156,  1.7363],
         [-0.2173,  1.6178,  0.3803],
         [ 1.0066, -0.1525,  0.9909],
         [-0.2188,  2.3243, -0.2126],
         [ 1.0174,  0.5062,  0.8094],
         [ 0.5706,  0.8641,  0.4400],
         [-0.4044,  0.4244,  1.0195],
         [-0.9460,  0.2610, -0.7557],
         [ 0.2741,  2.3303,  1.1549],
         [-0.0166, -0.5541,  0.1172],
         [-0.2707,  0.7538,  0.7564],
         [ 0.4594,  1.8595, -0.3041],
         [ 0.3454, -0.1474,  0.6824],
         [-0.0069,  0.4181,  0.3163],
         [ 1.0026,  1.2713, -0.8654],
         [ 0.3445,  1.8620,  0.1051],
         [-0.3438, -0.2148,  1.1608],
         [-0.5543,  0.5251,  0.2278],
         [ 0.1633,  0.4756, -0.1548],
         [-0.8429,  1.6435,  0.6730],
         [ 1.0275,  1.8898,  0.7942],
         [ 0.0942,  1.7555,  0.2015],
         [ 0.6542,  0.4129, -0.1839],
         [ 1.0795,  0.8736,  1.4901],
         [-0.8609,  1.6039,  0.6212],
         [ 1.0062,  0.0486, -0.3058],
         [ 1.2078, -0.6607,  0.3364],
         [ 0.2110,  1.1071, -0.4464],
         [ 0.6353,  1.2852,  0.0100],
         [ 1.0187, -0.1107,  1.0110],
         [ 0.3929,  1.3622,  1.2969],
         [-0.5859,  1.7405,  0.9156],
         [ 0.1505,  1.0312,  0.9133],
         [-0.4072,  1.6853,  1.2086],
         [ 0.7048,  1.0480,  1.5260],
         [-0.8025,  0.3658,  0.7118],
         [-0.2218,  0.5643,  1.7395],
         [ 0.8553,  1.0807, -0.8428],
         [ 0.1409,  2.3352,  0.0092],
         [-0.2802,  0.9718,  1.9523],
         [ 0.2378,  0.4535,  0.3162],
         [-0.4636,  1.5604,  0.5048],
         [-0.6213,  0.4753,  0.6231],
         [-1.2055,  0.4623,  0.3475],
         [ 0.2762,  0.4307,  0.7012],
         [-0.5780,  1.2657,  0.7372],
         [-0.2701,  1.2160, -0.0193],
         [ 0.3991,  1.7949,  1.2491],
         [ 0.6195,  0.4259, -0.4820],
         [ 0.5378, -0.3186,  1.7613],
         [ 0.1508,  1.6295,  1.7846],
         [-0.4579,  2.2713,  0.4456],
         [ 0.2987,  0.9656,  0.9261],
         [ 0.3407,  0.2929, -0.9976],
         [-0.1784,  0.4960, -0.0383],
         [-0.4151,  1.3423, -0.2520],
         [ 0.5688,  0.4744,  1.0954],
         [-0.8336, -0.3648,  0.2728],
         [ 1.2328,  0.1558,  0.1055],
         [-0.5703,  0.8411,  0.5249],
         [ 0.5890,  0.7854,  0.6073],
         [-0.3158,  0.5958,  0.4018],
         [ 0.0311,  0.3421, -0.1663],
         [ 0.2112,  0.7417,  1.2552],
         [-0.4835,  0.4369,  1.8484],
         [-1.1536,  0.4475,  1.2496],
         [ 0.3670,  1.4934, -0.3821],
         [-0.3714,  1.3760, -0.2266],
         [-0.3410,  0.1890,  1.3774],
         [ 1.4420,  0.4318,  0.9170],
         [ 0.0438,  0.0739,  0.2453],
         [-0.2960,  1.4054,  1.9589],
         [-0.4699,  0.7405,  0.5207],
         [-0.3494,  0.9814,  0.7333],
         [ 0.4671,  1.6039,  0.4615],
         [-0.0045,  0.2771,  0.3593],
         [ 0.2895,  0.8955,  0.3563],
         [-1.2088,  1.9607, -0.0584],
         [-0.0386,  1.6715,  1.1514],
         [ 0.1920, -0.1889,  0.8102],
         [ 0.1728, -0.5869,  1.3277],
         [-0.2620,  0.4226,  0.8173],
         [ 1.0984,  1.4860,  0.1200],
         [-0.4569, -0.0104,  0.3258],
         [-0.4865,  0.8544,  0.1088],
         [-0.0793,  0.7678, -0.3970],
         [ 0.1500,  0.0693, -0.6726],
         [-0.2643, -0.9343,  0.1285],
         [ 0.5117,  1.9405,  0.1496],
         [ 0.5586,  0.4971,  1.3617],
         [-0.4120,  0.8306, -0.3546],
         [ 0.2389,  1.9273,  0.0203],
         [-0.4329,  0.8439,  1.1402],
         [ 0.6105, -0.0550,  1.1159],
         [-0.1237,  1.4937, -0.0921],
         [-0.8427,  0.5847, -0.3854],
         [ 0.4284,  1.1857,  1.0030],
         [-0.3376,  1.0021,  1.1905],
         [ 0.5244, -0.0773,  1.1027],
         [ 0.3485,  1.0351,  0.3159],
         [-1.0741,  0.5730,  0.9853],
         [-0.5350,  1.1966,  1.3105],
         [-0.6670, -0.3987, -0.2548],
         [-0.6548,  1.3346,  0.6659],
         [-0.4622,  1.5058,  1.4348],
         [ 0.7942,  1.5803,  0.1862],
         [-0.5989,  0.7958,  0.8229],
         [ 0.3099,  1.5816,  0.9404]]], device='cuda:0',
       grad_fn=<AddBackward0>)
heading_scores tensor([[[-0.2943,  0.5445,  0.1302,  ...,  0.2182,  0.0757, -0.2836],
         [ 0.0283,  0.5994,  0.1035,  ..., -0.1855, -0.1230, -0.0206],
         [ 0.0897,  1.1202, -0.4057,  ..., -0.4876,  0.2602,  0.2544],
         ...,
         [ 0.0524,  0.1152, -0.1974,  ..., -0.6641,  0.3343, -0.2976],
         [-0.3986,  0.6704, -0.6342,  ..., -0.6011, -0.0332, -0.2879],
         [-0.3802,  0.5259, -0.1690,  ..., -0.0830, -0.5511, -0.4446]]],
       device='cuda:0', grad_fn=<SliceBackward>)
heading_residuals_normalized tensor([[[ 0.0381, -0.4776, -0.2103,  ...,  0.2547,  0.5106, -0.1611],
         [ 0.0405,  0.2786, -0.5760,  ..., -0.3753,  0.2387, -0.2561],
         [-0.7437, -0.2088, -0.4112,  ...,  0.4934,  0.9573, -0.6590],
         ...,
         [-0.3112, -0.3960, -0.4922,  ...,  0.3611,  0.0551, -0.3722],
         [-0.5016,  0.2315,  0.4729,  ...,  0.2754,  0.5301, -0.9247],
         [ 0.0841, -0.3604, -0.0060,  ...,  0.2263,  0.0591, -0.3428]]],
       device='cuda:0', grad_fn=<SliceBackward>)
heading_residuals tensor([[[ 0.0100, -0.1250, -0.0550,  ...,  0.0667,  0.1337, -0.0422],
         [ 0.0106,  0.0729, -0.1508,  ..., -0.0982,  0.0625, -0.0670],
         [-0.1947, -0.0547, -0.1077,  ...,  0.1292,  0.2506, -0.1725],
         ...,
         [-0.0815, -0.1037, -0.1289,  ...,  0.0945,  0.0144, -0.0974],
         [-0.1313,  0.0606,  0.1238,  ...,  0.0721,  0.1388, -0.2421],
         [ 0.0220, -0.0944, -0.0016,  ...,  0.0592,  0.0155, -0.0897]]],
       device='cuda:0', grad_fn=<MulBackward0>)
size_scores tensor([[[ 0.0273, -0.2626, -0.1797,  ..., -0.7649, -0.3965, -0.7755],
         [ 0.5995, -0.2994, -0.1223,  ...,  0.0454, -0.0240, -0.4289],
         [ 1.1605, -0.5132,  0.3192,  ...,  0.4814, -0.2610, -0.5116],
         ...,
         [-0.4790, -0.1590, -0.1086,  ..., -0.1359, -0.1656, -0.3194],
         [ 0.3601, -0.5028,  0.5221,  ..., -0.0159, -0.7329,  0.1229],
         [ 0.6852, -0.7212, -0.0225,  ...,  0.0426,  0.2000, -0.1524]]],
       device='cuda:0', grad_fn=<SliceBackward>)
size_residuals_normalized tensor([[[[-0.2169,  0.1220, -0.1374],
          [ 0.8310,  0.0899, -0.0798],
          [ 0.8615, -0.4519,  0.2676],
          ...,
          [-0.2967, -0.2468, -0.0721],
          [ 0.5859,  0.4545,  0.0630],
          [ 0.5972,  0.5554,  0.1469]],

         [[-0.0443,  0.1178, -0.0112],
          [ 0.4318, -0.0210,  0.3523],
          [-0.2915, -0.9794,  0.3721],
          ...,
          [ 0.5718, -0.3166, -0.3195],
          [ 0.5810,  0.2642, -0.0471],
          [-0.0885, -0.2259,  0.4313]],

         [[-0.1286,  0.7658,  0.9077],
          [ 0.5042,  0.3047, -0.2067],
          [-0.7701, -0.4005, -0.2352],
          ...,
          [ 0.9537, -0.1927,  0.1849],
          [ 0.6098,  0.5264,  0.2447],
          [-0.1361,  0.2498,  0.4496]],

         ...,

         [[-0.0834,  0.7152,  0.2648],
          [ 0.6666,  0.4176,  0.2650],
          [ 0.2320, -0.2836,  0.1975],
          ...,
          [ 0.5276,  0.2312, -0.0495],
          [-0.1970,  0.2614,  0.3735],
          [-0.0636,  0.3402,  0.2598]],

         [[-0.3298,  0.5477, -0.3374],
          [ 0.7294,  0.0626,  0.6778],
          [ 1.3968, -0.5022,  0.8090],
          ...,
          [ 0.3713, -0.2328,  0.2789],
          [ 0.2360, -0.1779,  0.1576],
          [-0.1451, -0.0181,  0.3030]],

         [[-0.1963, -0.2653, -0.2058],
          [ 0.0945,  0.1458,  0.0570],
          [ 0.1922, -0.2907,  0.2571],
          ...,
          [ 0.2539, -0.1484,  0.3186],
          [ 0.0741,  0.4011,  0.4157],
          [ 0.1385,  0.5137, -0.0764]]]], device='cuda:0',
       grad_fn=<ViewBackward>)
size_residuals tensor([[[[-0.0432,  0.0977, -0.1159],
          [ 0.0363,  0.0853, -0.0073],
          [ 0.4685, -0.1863,  0.0605],
          ...,
          [-0.0222, -0.1181, -0.0268],
          [ 0.0652,  0.2142,  0.0462],
          [ 0.2549,  0.3176,  0.0881]],

         [[-0.0088,  0.0943, -0.0095],
          [ 0.0188, -0.0199,  0.0324],
          [-0.1585, -0.4038,  0.0842],
          ...,
          [ 0.0427, -0.1515, -0.1187],
          [ 0.0646,  0.1245, -0.0346],
          [-0.0378, -0.1291,  0.2587]],

         [[-0.0256,  0.6132,  0.7653],
          [ 0.0220,  0.2891, -0.0190],
          [-0.4187, -0.1651, -0.0532],
          ...,
          [ 0.0712, -0.0922,  0.0687],
          [ 0.0678,  0.2481,  0.1795],
          [-0.0581,  0.1428,  0.2696]],

         ...,

         [[-0.0166,  0.5727,  0.2232],
          [ 0.0291,  0.3962,  0.0243],
          [ 0.1261, -0.1169,  0.0447],
          ...,
          [ 0.0394,  0.1106, -0.0184],
          [-0.0219,  0.1232,  0.2741],
          [-0.0272,  0.1945,  0.1558]],

         [[-0.0657,  0.4386, -0.2845],
          [ 0.0318,  0.0594,  0.0623],
          [ 0.7596, -0.2071,  0.1830],
          ...,
          [ 0.0277, -0.1114,  0.1036],
          [ 0.0262, -0.0838,  0.1157],
          [-0.0619, -0.0103,  0.1817]],

         [[-0.0391, -0.2125, -0.1735],
          [ 0.0041,  0.1384,  0.0052],
          [ 0.1045, -0.1198,  0.0581],
          ...,
          [ 0.0190, -0.0710,  0.1184],
          [ 0.0082,  0.1890,  0.3050],
          [ 0.0591,  0.2937, -0.0458]]]], device='cuda:0',
       grad_fn=<MulBackward0>)
sem_cls_scores tensor([[[-0.3198, -0.1493, -0.7164,  ..., -0.1005,  0.3438,  0.2380],
         [ 0.4669, -0.1449, -0.5903,  ...,  0.1016,  0.5922, -0.2003],
         [ 0.1515,  0.2803,  0.5777,  ...,  0.5044,  0.7114,  0.5654],
         ...,
         [ 0.1133,  0.4271, -0.2801,  ...,  0.7212,  0.2191,  0.1871],
         [-0.2420, -0.4451, -0.9502,  ...,  0.6865,  0.1480, -0.0759],
         [-0.3448, -0.2007, -0.4305,  ...,  0.2229,  0.0190,  0.5149]]],
       device='cuda:0', grad_fn=<SliceBackward>)
Dataset has not been prepared. Skip loss and dump.
